import pandas as pd
import string
df = pd.read_csv("books_dataset.csv")
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style('whitegrid')

df = pd.read_csv('books_dataset.csv')
print(df.head())

df.rename(columns={"User Rating": "User_Rating"}, inplace=True)
df[df.Author == 'J. K. Rowling']
df[df.Author == 'J.K. Rowling']
df.loc[df.Author == 'J. K. Rowling', 'Author'] = 'J.K. Rowling'
df['name_len'] = df['Name'].apply(lambda x: len(x) - x.count(" "))
punctuations = string.punctuation
print('list of punctuations : ', punctuations)


def count_punc(text):
    """This function counts the number of punctuations in a text"""
    count = sum(1 for char in text if char in punctuations)
    return round(count/(len(text) - text.count(" "))*100, 3)

df['punc%'] = df['Name'].apply(lambda x: count_punc(x))

no_dup = df.drop_duplicates('Name')
g_count = no_dup['Genre'].value_counts()

fig, ax = plt.subplots(figsize=(8, 8))

def make_autopct(values):
    def my_autopct(pct):
        total = sum(values)
        val = int(round(pct*total/100.0))
        return '{p:.2f}%\n({v:d})'.format(p=pct,v=val)
    return my_autopct

genre_col = ['navy','crimson']
#genre_col = ['khaki','plum']

center_circle = plt.Circle((0, 0), 0.7, color='white')
plt.pie(x=g_count.values, labels=g_count.index, autopct=make_autopct(g_count.values),
          startangle=90, textprops={'size': 15}, pctdistance=0.5, colors=genre_col)
ax.add_artist(center_circle)

fig.suptitle('Distribution of Genre for all unique books from 2009 to 2019', fontsize=20)
fig.show()

y1 = np.arange(2009, 2014)
y2 = np.arange(2014, 2020)
g_count = df['Genre'].value_counts()

fig, ax = plt.subplots(2, 6, figsize=(12,6))

ax[0,0].pie(x=g_count.values, labels=None, autopct='%1.1f%%',
            startangle=90, textprops={'size': 12, 'color': 'white'},
            pctdistance=0.5, radius=1.3, colors=genre_col)
ax[0,0].set_title('2009 - 2019\n(Overall)', color='darkgreen', fontdict={'fontsize': 15})

for i, year in enumerate(y1):
    counts = df[df['Year'] == year]['Genre'].value_counts()
    ax[0,i+1].set_title(year, color='darkred', fontdict={'fontsize': 15})
    ax[0,i+1].pie(x=counts.values, labels=None, autopct='%1.1f%%',
                  startangle=90, textprops={'size': 12,'color': 'white'},
                  pctdistance=0.5, colors=genre_col, radius=1.1)

for i, year in enumerate(y2):
    counts = df[df['Year'] == year]['Genre'].value_counts()
    ax[1,i].pie(x=counts.values, labels=None, autopct='%1.1f%%',
                startangle=90, textprops={'size': 12,'color': 'white'},
                pctdistance=0.5, colors=genre_col, radius=1.1)
    ax[1,i].set_title(year, color='darkred', fontdict={'fontsize': 15})

#plt.suptitle('Distribution of Fiction and Non-Fiction books for every year from 2009 to 2019',
             #fontsize=25)
fig.legend(g_count.index, loc='center right', fontsize=12)
fig.show()

best_nf_authors = df.groupby(['Author', 'Genre']).agg({'Name': 'count'}).unstack()['Name', 'Non Fiction'].sort_values(ascending=False)[:11]
best_f_authors = df.groupby(['Author', 'Genre']).agg({'Name': 'count'}).unstack()['Name', 'Fiction'].sort_values(ascending=False)[:11]

with plt.style.context('Solarize_Light2'):
    fig, ax = plt.subplots(1, 2, figsize=(8,8))

    ax[0].barh(y=best_nf_authors.index, width=best_nf_authors.values,
           color=genre_col[0])
    ax[0].invert_xaxis()
    ax[0].yaxis.tick_left()
    ax[0].set_xticks(np.arange(max(best_f_authors.values)+1))
    ax[0].set_yticklabels(best_nf_authors.index, fontsize=12, fontweight='semibold')
    ax[0].set_xlabel('Number of appreances')
    ax[0].set_title('Non Fiction Authors')

    ax[1].barh(y=best_f_authors.index, width=best_f_authors.values,
           color=genre_col[1])
    ax[1].yaxis.tick_right()
    ax[1].set_xticks(np.arange(max(best_f_authors.values)+1))
    ax[1].set_yticklabels(best_f_authors.index, fontsize=12, fontweight='semibold')
    ax[1].set_title('Fiction Authors')
    ax[1].set_xlabel('Number of appreances')

    fig.legend(['Non Fiction', 'Fiction'], fontsize=12)

plt.show()


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
import numpy as np

df = pd.read_csv("books_dataset.csv")


feature_pairs = [
    ("Price", "User Rating"),
    ("Price", "Reviews"),
    ("Year", "User Rating"),
]


for x_col, y_col in feature_pairs:
    X = df[[x_col]].values
    y = df[y_col].values

    model = LinearRegression()
    model.fit(X, y)

  
    x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
    y_pred = model.predict(x_range)

   
    plt.figure(figsize=(8, 6))
    sns.scatterplot(x=df[x_col], y=df[y_col], alpha=0.5)
    plt.plot(x_range, y_pred, color="red", linewidth=2)
    plt.xlabel(x_col)
    plt.ylabel(y_col)
    plt.title(f"Linear Regression: {x_col} vs {y_col}")
    plt.show()



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv('books_dataset.csv')


print("Dataset shape:", df.shape)
print(df.head())


numeric_df = df.select_dtypes(include=['float64', 'int64'])


corr = numeric_df.corr()

plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)


plt.title('Correlation Heatmap of Amazon Bestsellers (2019â€“2024)', fontsize=14, pad=15)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()


plt.show()


sns.scatterplot(data=df, x='Price', y='Reviews', hue='Genre', alpha=0.7)
plt.title("Price vs Reviews (Popularity)")
plt.show()

from wordcloud import WordCloud

text = " ".join(df['Name'])
wordcloud = WordCloud(width=1000, height=600, background_color='white').generate(text)

plt.figure(figsize=(10,6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Most Frequent Words in Bestseller Titles", fontsize=16)
plt.show()




from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


df['High_Rated'] = (df['User Rating'] >= 4.5).astype(int)
genre_encoder = LabelEncoder()
df['Genre_Encoded'] = genre_encoder.fit_transform(df['Genre'])

# Select features for classification
X = df[['Price', 'Reviews', 'Year', 'Genre_Encoded']]
y = df['High_Rated']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

# Logistic Regression Model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:", confusion_matrix(y_test, y_pred))
print("Classification Report:", classification_report(y_test, y_pred))



import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, accuracy_score
import string


df2 = df.copy()



# Title length in characters (no spaces)
df2["title_len"] = df2["Name"].apply(lambda x: len(x.replace(" ", "")))

# Word count in title
df2["word_count"] = df2["Name"].apply(lambda x: len(x.split()))

# Punctuation %
punct = string.punctuation
def punctuation_percent(text):
    count = sum(1 for ch in text if ch in punct)
    length = len(text) - text.count(" ")
    return round((count / length) * 100, 3)

df2["punctuation_percent"] = df2["Name"].apply(punctuation_percent)

# Encode categorical features
genre_encoder2 = LabelEncoder()
author_encoder2 = LabelEncoder()

df2["Genre_Encoded2"] = genre_encoder2.fit_transform(df2["Genre"])
df2["Author_Encoded2"] = author_encoder2.fit_transform(df2["Author"])


median_reviews = df2["Reviews"].median()

df2["Is_Bestseller"] = (
    (df2["User Rating"] >= 4.5) &
    (df2["Reviews"] >= median_reviews)
).astype(int)


 
new_features = [
    "Price",
    "Reviews",
    "User Rating",
    "Year",
    "Genre_Encoded2",
    "Author_Encoded2",
    "title_len",
    "word_count",
    "punctuation_percent"
]

X2 = df2[new_features]
y2 = df2["Is_Bestseller"]

X_train2, X_test2, y_train2, y_test2 = train_test_split(
    X2, y2, test_size=0.25, random_state=42
)


rf2 = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=42)
rf2.fit(X_train2, y_train2)

gb2 = GradientBoostingClassifier(random_state=42)
gb2.fit(X_train2, y_train2)



print("Accuracy:", accuracy_score(y_test2, rf2.predict(X_test2)))
print(classification_report(y_test2, rf2.predict(X_test2)))

print("\nðŸ“Œ Gradient Boosting Performance:")
print("Accuracy:", accuracy_score(y_test2, gb2.predict(X_test2)))
print(classification_report(y_test2, gb2.predict(X_test2)))


import matplotlib.pyplot as plt

importances2 = rf2.feature_importances_
sorted_idx = np.argsort(importances2)[::-1]

plt.figure(figsize=(8,5))
plt.barh([new_features[i] for i in sorted_idx], importances2[sorted_idx])
plt.gca().invert_yaxis()
plt.title("Top Factors That Predict a Bestseller")
plt.xlabel("Importance Score")
plt.show()



def predict_bestseller(name, price, reviews, rating, year, genre, author):
    
    
    title_len = len(name.replace(" ", ""))
    word_count = len(name.split())
    punct_per = punctuation_percent(name)

    genre_val = genre_encoder2.transform([genre])[0]
    author_val = author_encoder2.transform([author])[0]

    sample = np.array([[
        price, reviews, rating, year,
        genre_val, author_val,
        title_len, word_count, punct_per
    ]])

    prob = rf2.predict_proba(sample)[0][1]
    prediction = "LIKELY Bestseller" if prob >= 0.55 else "Not Likely"

    return {
        "Prediction": prediction,
        "Confidence": round(prob * 100, 2)
    }




print(
    predict_bestseller(
        name="The Silent Patient",
        price=14,
        reviews=18000,
        rating=4.7,
        year=2022,
        genre="Fiction",
        author="Alex Michaelides"
    )
)





from sklearn.ensemble import RandomForestClassifier


X = df[['Price', 'Reviews', 'User Rating', 'Year']]
y = df['Genre_Encoded']


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)


rf_model = RandomForestClassifier(
    n_estimators=200,
    random_state=42
)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)


print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:", classification_report(y_test, y_pred_rf))

import matplotlib.pyplot as plt

importances = rf_model.feature_importances_
features = X.columns

plt.figure(figsize=(8,5))
plt.barh(features, importances)
plt.xlabel("Importance Score")
plt.title("Feature Importance for Genre Classification")
plt.show()
